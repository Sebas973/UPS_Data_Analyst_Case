{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384c7602-bebf-42f6-bd19-7ac96b69ffe6",
   "metadata": {},
   "source": [
    "# UPS BR Data Analyst Case:\n",
    "## Python Challenge\n",
    "\n",
    "**By Sebastian Montero Segura**\n",
    "\n",
    "In this challenge, you are presented another fictitious data sample, that mocks customer\n",
    "purchases and deliveries. I this hypothetical scenario, the company wants to develop a\n",
    "machine-learning model to predict a delivery delay and notify the customer in advance.\n",
    "Based on the file provided (predict-model-dataset.csv), the minimum request for this\n",
    "challenge is to answer the following questions using Python:\n",
    "\n",
    ">1. Which Warehouse has more delays? Absolute and relative (%)\n",
    "\n",
    ">2. Which Transportation mode has more delays? Absolute and relative (%)\n",
    "\n",
    ">3. Generate a visuals to illustrate the distributions of “Gender” x “Customer_Rating”\n",
    "\n",
    ">4. Based on the data provided, does package weight seems to be related to the delivery\n",
    "delay?\n",
    "\n",
    "The extra request for this challenge is:\n",
    "\n",
    ">►Provide an overall data exploration, using Python. Metrics such mean, max, min,\n",
    "std_deviation;\n",
    "\n",
    ">►Predict model and its respective scores (Accuracy, Precision, Recall, F1-Score, ROC,\n",
    "Confusion Matrix, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d58fe-a357-4818-af94-3431886734c3",
   "metadata": {},
   "source": [
    "### 1.Import the Data:\n",
    "►Import Python Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0d29fee-2e76-4dd3-b000-f450d79fe475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd6e33-1e15-4ea6-8a4e-d809bcf08ad6",
   "metadata": {},
   "source": [
    "►Read CSV file from Github Repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646fa26c-d472-4993-a35e-0702987eb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_URL = \"https://raw.githubusercontent.com/juanrodriguesups/UPS-BR-Data-Analytics-Case/main/predict-model-dataset.csv\"\n",
    "file_URL = \"./predict-model-dataset.csv\"\n",
    "df_predict_model = pd.read_csv(file_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af2578c-bcd7-4ed7-b99a-250a2ae43441",
   "metadata": {},
   "source": [
    "### 2. Clean the Data\n",
    "►Verify that the datatypes imported of the Dataframe columns match the types that we are expecting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280d24d-302e-4756-823f-dba027e5e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc8928-df60-4e96-87ad-ddf0e3d99a28",
   "metadata": {},
   "source": [
    "►Check for null Values in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a9039-f020-4986-ab67-278b7e9731ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df_predict_model).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a525a-46d1-40a0-98f2-ccaa9f1fa49d",
   "metadata": {},
   "source": [
    "### 3. Analysis of the Data\n",
    "#### 1. Which Warehouse has more delays? Absolute and relative (%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbccb4db-de3c-4acc-a836-be6ce50484bb",
   "metadata": {},
   "source": [
    "First we'll need to count the number of delays registered in the data grouped by warehouse in order to get the absolute number of delays.\n",
    "For this, the variable 'result_warehouse_delays' is going to store the count of registers where the 'DELIVERY_DELAYED' is equal to 0, grouped by each unique 'WAREHOUSE_BLOCK' in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "525d9b61-d3ab-4d41-a5f6-8ca497d2d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_warehouse_delays = df_predict_model.loc[df_predict_model['DELIVERY_DELAYED'] == 0, ['WAREHOUSE_BLOCK','DELIVERY_DELAYED']].groupby('WAREHOUSE_BLOCK').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50554c-1f6c-4a56-8fc3-623f8556a8a0",
   "metadata": {},
   "source": [
    "Second, to discover the relative percentage of delays for each depot we'll need to have the total amount of delays, to later divide the delays for each warehouse between the total of delays and multiply it by 100. The total sum of delays is going to be stored in the vaiable 'Total_Delays'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f3e246d-c8be-4426-a38e-c88d2798a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_delays = result_warehouse_delays['DELIVERY_DELAYED'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c3e62-4d3e-458d-b2d5-c63d7795a07b",
   "metadata": {},
   "source": [
    "To store the results of the calculation of the relative delays per warehouse, we create new column in the dataframe called 'RELATIVE_DELAY':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f807c66a-abcb-4dc6-a958-2763982c6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_warehouse_delays['RELATIVE_DELAY'] = (result_warehouse_delays['DELIVERY_DELAYED'] / total_delays) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c80769",
   "metadata": {},
   "source": [
    "When creating the chart we'll need the unique values of warehouse to use as reference of the 'X' axis in the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfeb2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse = df_predict_model['WAREHOUSE_BLOCK'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c200d76-a4f2-4df1-b354-cdf41d66232e",
   "metadata": {},
   "source": [
    "And to finish, once we have all the absolute and relative measures for each depot it's time to create some visualizations of the data to have a better understanding of the data:\n",
    "\n",
    "**Bar chart / Absolute Delays per Warehouse:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb5d2f-597d-46e8-97ff-b4769989ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(warehouse, result_warehouse_delays['DELIVERY_DELAYED'])\n",
    "plt.title('Absolute Delays per Warehouse')\n",
    "plt.ylabel('Total Delays')\n",
    "plt.xlabel('Warehouse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c66c8e-0d46-4635-bc9a-b4608b9fc4c0",
   "metadata": {},
   "source": [
    "**Pie chart / Relative % Delays per Warehouse:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac780495-5806-44c6-8799-6b2ef7aee413",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.pie(result_warehouse_delays['RELATIVE_DELAY'], labels = warehouse, autopct = '%.2f %%')\n",
    "plt.title('Relative % Delays per Warehouse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf65f8",
   "metadata": {},
   "source": [
    "#### 2. Which Transportation mode has more delays? Absolute and relative (%)\n",
    "\n",
    "As in the case before, we need to count the number of delays registered in the data grouped by Transportation Mode in order to get the absolute number of delays.\n",
    "For this, the variable 'result_transportation_delays' is going to store the count of registers where the 'DELIVERY_DELAYED' is equal to 0, grouped by each unique 'MODE_OF_SHIPMENT' in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e691dc26-ca38-4360-9684-1b694c1532fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_transportation_delays = df_predict_model.loc[df_predict_model['DELIVERY_DELAYED'] == 0, ['MODE_OF_SHIPMENT','DELIVERY_DELAYED']].groupby('MODE_OF_SHIPMENT').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ab1e",
   "metadata": {},
   "source": [
    "Second, to discover the relative percentage of delays for each depot we'll need to have the total amount of delays, to later divide the delays for each Transportation Mode between the total of delays and multiply it by 100. The total sum of delays is going to be stored in the vaiable 'total_delays':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38b77f61-ccff-4e76-999f-3650c5e760ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_delays = result_transportation_delays['DELIVERY_DELAYED'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c2b85",
   "metadata": {},
   "source": [
    "To store the results of the calculation of the relative delays per shipment mode, we create new column in the dataframe called 'RELATIVE_DELAY':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a43ae40-c82d-4a52-bb47-5d65bfb2a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_transportation_delays['RELATIVE_DELAY'] = (result_transportation_delays['DELIVERY_DELAYED'] / total_delays) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6e26d",
   "metadata": {},
   "source": [
    "When creating the chart we'll need the unique values of shipment mode to use as reference of the 'X' axis in the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99b59f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "transportation = df_predict_model['MODE_OF_SHIPMENT'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20da040",
   "metadata": {},
   "source": [
    "And to finish, once we have all the absolute and relative measures for each Transportation Mode it's time to create some visualizations of the data to have a better understanding of the data:\n",
    "\n",
    "**Bar chart / Absolute Delays per Transportation Mode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15ae5e-3c58-42fc-90a1-27c5caf2de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(transportation, result_transportation_delays['DELIVERY_DELAYED'])\n",
    "plt.title('Absolute Delays per Transportation Mode')\n",
    "plt.ylabel('Total Delays')\n",
    "plt.xlabel('Transportation Mode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d940fa06",
   "metadata": {},
   "source": [
    "**Pie chart / Relative % Delays per Transportation Mode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d809e2b-e249-4bab-8692-d379cc207ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.pie(result_transportation_delays['RELATIVE_DELAY'], labels = transportation, autopct = '%.2f %%')\n",
    "plt.title('Relative % Delays per Transportation Mode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c654e",
   "metadata": {},
   "source": [
    "#### 3. Generate a visuals to illustrate the distributions of “Gender” x “Customer_Rating”\n",
    "\n",
    "To generate a chart that displays the distribution of Customer Ratings per Gender, we'll create a new dataframe that is going to store the count of ratings per gender grouped by the Ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "174c6da4-c871-4392-b0a1-4dd555181284",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ratingxgender =  df_predict_model.loc[df_predict_model['GENDER'] == 'F',['CUSTOMER_RATING','GENDER']].groupby('CUSTOMER_RATING').count()\n",
    "count_ratingxgender = count_ratingxgender.rename(columns={'GENDER': 'Female'})\n",
    "count_ratingxgender['Male'] =  df_predict_model.loc[df_predict_model['GENDER'] == 'M',['CUSTOMER_RATING','GENDER']].groupby('CUSTOMER_RATING').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then display the chart using the previous data set with a plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54759442",
   "metadata": {},
   "source": [
    "**Bar chart / Costumer ratings per Gender:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ratingxgender.plot(kind = 'bar')\n",
    "plt.xticks(range(0,6), rotation = 'horizontal')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Customer Rating')\n",
    "plt.title('Customer Ratings per Gender')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6398b43",
   "metadata": {},
   "source": [
    "#### 4.  Based on the data provided, does package weight seems to be related to the delivery delay?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a new DataFrame to store the weight and Delay columns, we'll find the Correlation coeficient using pythons correlation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd41195-5990-4643-9a2a-8e212b31de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Weight_x_Delay = pd.DataFrame()\n",
    "df_Weight_x_Delay['Weight'] = df_predict_model.WEIGHT_IN_GMS\n",
    "df_Weight_x_Delay['Delay'] = df_predict_model.DELIVERY_DELAYED\n",
    "corr_matrix = df_Weight_x_Delay.corr()\n",
    "print(corr_matrix['Delay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the correlation coefficient is a total of -0.27, between the weight and the delay exists a weak negative correlation, this means that if the weight value increases and viceversa, the delay value decreases, and in this case since the delay value for delay equals to 0, when the weight increases the delay value gets closer to 0 that its a delay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra\n",
    "#### ►Provide an overall data exploration, using Python. Metrics such mean, max, min, std_deviation;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a overall analysis of the numerical values in the data, we can do that with the describe() function of pandas. This will show us the count, mean, std_deviation, min, max for the columns that contain numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ►Predict model and its respective scores (Accuracy, Precision, Recall, F1-Score, ROC,Confusion Matrix, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Predict Model we first need to find the columns in our data set that are going to be useful in our prediction, this to avoid unnecessary information interfiering with our scores.\n",
    "\n",
    "Once identified the columns that we are going to use, we need to check if any of the selected columns contains categorical data, since this information can't be read by the predict model.\n",
    "\n",
    "To avoid this issue, the columns containing the categorical data are going to be droped and replaced by columns of each categorical value where its going to use \"True\" and \"False\" to identify the data in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbff4ca9-4c87-4f73-b19b-750e804d2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = df_predict_model.join(pd.get_dummies(df_predict_model.WAREHOUSE_BLOCK)).drop(['WAREHOUSE_BLOCK'], axis=1)\n",
    "Train_data = Train_data.join(pd.get_dummies(df_predict_model.MODE_OF_SHIPMENT)).drop(['MODE_OF_SHIPMENT'], axis=1)\n",
    "Train_data = Train_data.join(pd.get_dummies(df_predict_model.PRODUCT_IMPORTANCE)).drop(['PRODUCT_IMPORTANCE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the categorical columns are replaced, its time to drop the columns that are not necessary for the model and the column of the measure that we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8630742e-8a74-4875-898a-e90157ce88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = Train_data.drop(['ID'], axis=1)\n",
    "Train_data = Train_data.drop(['CUSTOMER_RATING'], axis=1)\n",
    "Train_data = Train_data.drop(['COST_OF_THE_PRODUCT'], axis=1)\n",
    "Train_data = Train_data.drop(['DISCOUNT_OFFERED'], axis=1)\n",
    "Train_data = Train_data.drop(['GENDER'], axis=1)\n",
    "Train_data = Train_data.drop(['DELIVERY_DELAYED'], axis=1)\n",
    "Train_data = Train_data.drop(['CUSTOMER_CARE_CALLS'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import the necessary methods for our Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into test sets and train sets, we'll train our model with our training sets and then test the results of the predictions in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Train_data, df_predict_model['DELIVERY_DELAYED'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load our prediction model, in this case we'll use the logistic Regression model and then fit the training data in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training data fitted in the model, we proceed to make predictions in the fist test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to finish, we need to get our evaluation metrics using the predictions of the first test data and the second test data to compare its performace with a diferent test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf1481-e2c4-4327-88b0-24a5d146ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
